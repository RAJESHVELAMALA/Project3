{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzpq6iO8Kb0CEKNY7q4BFl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RAJESHVELAMALA/Project3/blob/main/ImageProcessingModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WYK-uDmaDJ_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fedc56a-56be-4fea-caab-4438c0ae1026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import requests\n",
        "import numpy as np\n",
        "import pickle\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import load_model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loadImages(path, filename):\n",
        "  print(\"Loading images...\")\n",
        "  print(\"Reading the meta file containing all image file names\")\n",
        "  filenames_df = pd.read_csv(path+filename)\n",
        "  base_path = path + \"Images/\"\n",
        "  print(filenames_df.shape)\n",
        " # Create a empty list to hold images\n",
        "  images = []\n",
        "  filenames_df_success = []\n",
        "\n",
        "  # Sort Dataset on id\n",
        "  #filenames_df = filenames_df.sort_values(by=['id'])\n",
        "  number_of_images = len(filenames_df)\n",
        "  #number_of_images = 25\n",
        "\n",
        "  for i in range(number_of_images):\n",
        "      filename = filenames_df.iloc[i,0]\n",
        "      path = base_path + filename+\".jpg\"\n",
        "      print(f'{i} of {len(filenames_df)}: Attempting to import {path}')\n",
        "      try:\n",
        "          images.append(Image.open(path))\n",
        "          filenames_df_success.append(filename)\n",
        "      except:\n",
        "          print(f'FAILED: {filename}')\n",
        "  print(len(filenames_df_success))\n",
        "  print(\"Images loaded!\" + str(len(images)))\n",
        "  return (images,filenames_df_success)\n",
        "\n",
        "\n",
        "#imageList,fileNameList = loadImages(\"/content/sample_data/\", \"FOODITEMS.csv\")"
      ],
      "metadata": {
        "id": "Hui3DcYU9W8t"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createPickle(images):\n",
        "  print(\"Creating pickle file...\")\n",
        "  with open('/content/drive/My Drive/food_imgages_project3.pkl', 'wb') as file:\n",
        "      pickle.dump(images, file)\n",
        "      print(\"Pickle file created!\")"
      ],
      "metadata": {
        "id": "1GwipoQk-OQS"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createPickleDF(filenames):\n",
        "  print(\"Creating pickle file...\")\n",
        "  filenames_df = pd.DataFrame(filenames)\n",
        "  pd.to_pickle(filenames_df, '/content/drive/My Drive/food_filenames_df_project3.pkl')\n",
        "  print(\"Pickle file created!\")\n"
      ],
      "metadata": {
        "id": "nyRe1fgip78Y"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadImagesFromPickle():\n",
        "  # Mount google drive\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  print(\"Loading images from pickle file...\")\n",
        "  with open('/content/drive/My Drive/food_imgages_project3.pkl', 'rb') as file:\n",
        "      images = pickle.load(file)\n",
        "  return images"
      ],
      "metadata": {
        "id": "_A37iSwT-z7g"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadFilenamesFromPickle():\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  print(\"Loading filenames from pickle file...\")\n",
        "  filenames_df = pd.read_pickle('/content/drive/My Drive/food_filenames_df_project3.pkl')\n",
        "  return filenames_df"
      ],
      "metadata": {
        "id": "Wwdox-SYqagJ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preProcessImages(imageList):\n",
        "  print(\"Preprocessing images...\")\n",
        "  # Resize images\n",
        "  target_size = (160, 160)\n",
        "  resized_images = [img.resize(target_size, resample = Image.LANCZOS) for img in faceImages]\n",
        "\n",
        "  # Convert all images to floating point numpy arrays\n",
        "  float_images = [np.array(img).astype(np.float32) for img in resized_images]\n",
        "\n",
        "  # To normalize images to a range between 0 and 1,\n",
        "  # we need to divide all pixel values by the max of 255\n",
        "\n",
        "  normalized_images = [img/255 for img in float_images]\n",
        "\n",
        "  # Display the pixel values of the first image\n",
        "  #print(normalized_images[0])\n",
        "\n",
        "  return normalized_images"
      ],
      "metadata": {
        "id": "Z6gYyHzqF-oA"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def enhanceDataSetForAugmentation(X_train,y_train):\n",
        "  # Apply augmentation to the whole training dataset\n",
        "  # Create an ImageDataGenerator\n",
        "  datagen = ImageDataGenerator(\n",
        "      rotation_range=20,      # Random rotation (degrees)\n",
        "      width_shift_range=0.1,  # Random horizontal shift\n",
        "      height_shift_range=0.1, # Random vertical shift\n",
        "      shear_range=0.2,        # Shear intensity\n",
        "      zoom_range=0.2,         # Random zoom\n",
        "      horizontal_flip=True,   # Random horizontal flip\n",
        "      vertical_flip=False,    # No vertical flip for face images\n",
        "      fill_mode='nearest'     # Fill mode for handling newly created pixels\n",
        "  )\n",
        "\n",
        "  # Create variables to hold the X and y training data\n",
        "  X_train_aug = []\n",
        "  y_train_aug = []\n",
        "  # Loop through all the images.\n",
        "  for i in range(len(X_train)):\n",
        "      # Select the image\n",
        "      img = X_train[i]\n",
        "      # Select the label from the training data\n",
        "      label = y_train[i]\n",
        "\n",
        "      # Add a channel dimension for grayscale images if needed\n",
        "      if img.ndim == 2:  # Check if it's grayscale (2 dimensions)\n",
        "          img = np.expand_dims(img, axis=-1)  # Add channel dimension\n",
        "\n",
        "      # Ensure that the input data has the correct shape (remove extra dimension)\n",
        "      # img = np.squeeze(img, axis=-1)  # Remove the extra dimension - Not needed anymore\n",
        "\n",
        "      # Add 5 images for every original image\n",
        "      for j in range(5):\n",
        "          # Append a new image to the X list\n",
        "          X_train_aug.append(next(datagen.flow(np.expand_dims(img, axis=0), batch_size=1))[0]) # Use next() to get the next item from the iterator\n",
        "          # Append the label for the original image to the y list - replicate the label for each augmented image\n",
        "          y_train_aug.append(label)\n",
        "\n",
        "  return X_train_aug, y_train_aug"
      ],
      "metadata": {
        "id": "ncLM0mDSz8sA"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createModel(X_train_aug, y_train_aug,epochs):\n",
        "  import tensorflow as tf\n",
        "  from tensorflow import keras\n",
        "  from tensorflow.keras import layers\n",
        "  from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "  from tensorflow.keras.optimizers import Adam\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  from sklearn.preprocessing import OneHotEncoder\n",
        "  import numpy as np\n",
        "\n",
        "  # One hot encode the y data\n",
        "  y_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False).fit(np.array(y_train_aug).reshape(-1, 1))\n",
        "  y_train_aug_enc = y_encoder.transform(np.array(y_train_aug).reshape(-1, 1))\n",
        "\n",
        "\n",
        "  # Convert values to numpy arrays\n",
        "  X_train_aug_np = np.array(X_train_aug)\n",
        "  y_train_aug_np = np.array(y_train_aug_enc)\n",
        "\n",
        "  # Load and preprocess your CMU Face Images dataset (Ensure each image is labeled as \"with sunglasses\" or \"without sunglasses\")\n",
        "  # The following code assumes that you have already loaded and preprocessed your dataset into 'X' and 'y' (features and labels).\n",
        "\n",
        "  # Split the training dataset into training and validation sets\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X_train_aug_np, y_train_aug_np, test_size=0.2, random_state=42)\n",
        "\n",
        "  # Define a CNN model\n",
        "  #model = keras.Sequential([\n",
        "  #    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),\n",
        "  ##    layers.MaxPooling2D((2, 2)),\n",
        "  #    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "  #    layers.MaxPooling2D((2, 2)),\n",
        "  #    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "  #    layers.Flatten(),\n",
        "  #    layers.Dense(64, activation='relu'),\n",
        "  ##    layers.Dense(64, activation='relu'),\n",
        "  #    layers.Dense(18, activation='sigmoid')  # Change to 18 classes to match your labels\n",
        "  #])\n",
        "\n",
        "  print(type(y_train))\n",
        "  print(y_train.shape[0],y_train.shape[1])\n",
        "  num_classes = y_train.shape[1]\n",
        "\n",
        "\n",
        "  # Define a CNN model\n",
        "  model = keras.Sequential([\n",
        "      layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),\n",
        "      #layers.MaxPooling2D((2, 2)),\n",
        "      layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "      #layers.MaxPooling2D((2, 2)),\n",
        "      #layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(64, activation='relu',kernel_regularizer=l2(0.0001)),\n",
        "      layers.Dense(num_classes, activation='sigmoid')  # Change to a single output node with sigmoid activation\n",
        "  ])\n",
        "  model.add(Dropout(0.5))  # Add dropout after a dense layer\n",
        "\n",
        "\n",
        "  reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=5, min_lr=0.001)\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  #model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, callbacks=[reduce_lr])\n",
        "\n",
        "  # Compile the model\n",
        "  #model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  # Train the model\n",
        "  batch_size = 10\n",
        "  epochs = epochs\n",
        "  history = model.fit(\n",
        "      X_train, y_train,\n",
        "      validation_data=(X_val, y_val),\n",
        "      epochs=epochs,\n",
        "      callbacks=[reduce_lr],\n",
        "      batch_size=batch_size\n",
        "  )\n",
        "\n",
        "  return model,y_encoder\n"
      ],
      "metadata": {
        "id": "QAYlsWwAzlHB"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#imageList,fileNameList = loadImages(\"/content/sample_data/\", \"Dataset.csv\")\n",
        "imageList,fileNameList = loadImages(\"/content/sample_data/\", \"FOODITEMS.csv\")\n",
        "\n",
        "createPickle(imageList)\n",
        "createPickleDF(fileNameList)\n"
      ],
      "metadata": {
        "id": "WTO7xr1wh7TH",
        "outputId": "ecfca988-698b-4056-bf75-b92526702d49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading images...\n",
            "Reading the meta file containing all image file names\n",
            "(100, 1)\n",
            "0 of 100: Attempting to import /content/sample_data/Images/baby_back_ribs.jpg\n",
            "1 of 100: Attempting to import /content/sample_data/Images/baklava.jpg\n",
            "2 of 100: Attempting to import /content/sample_data/Images/beef_carpaccio.jpg\n",
            "3 of 100: Attempting to import /content/sample_data/Images/beef_tartare.jpg\n",
            "4 of 100: Attempting to import /content/sample_data/Images/beet_salad.jpg\n",
            "5 of 100: Attempting to import /content/sample_data/Images/beignets.jpg\n",
            "6 of 100: Attempting to import /content/sample_data/Images/bibimbap.jpg\n",
            "7 of 100: Attempting to import /content/sample_data/Images/bread_pudding.jpg\n",
            "8 of 100: Attempting to import /content/sample_data/Images/breakfast_burrito.jpg\n",
            "9 of 100: Attempting to import /content/sample_data/Images/bruschetta.jpg\n",
            "10 of 100: Attempting to import /content/sample_data/Images/caesar_salad.jpg\n",
            "11 of 100: Attempting to import /content/sample_data/Images/cannoli.jpg\n",
            "12 of 100: Attempting to import /content/sample_data/Images/caprese_salad.jpg\n",
            "13 of 100: Attempting to import /content/sample_data/Images/carrot_cake.jpg\n",
            "14 of 100: Attempting to import /content/sample_data/Images/ceviche.jpg\n",
            "15 of 100: Attempting to import /content/sample_data/Images/cheesecake.jpg\n",
            "16 of 100: Attempting to import /content/sample_data/Images/cheese_plate.jpg\n",
            "17 of 100: Attempting to import /content/sample_data/Images/chicken_curry.jpg\n",
            "18 of 100: Attempting to import /content/sample_data/Images/chicken_quesadilla.jpg\n",
            "19 of 100: Attempting to import /content/sample_data/Images/chicken_wings.jpg\n",
            "20 of 100: Attempting to import /content/sample_data/Images/chocolate_cake.jpg\n",
            "21 of 100: Attempting to import /content/sample_data/Images/chocolate_mousse.jpg\n",
            "22 of 100: Attempting to import /content/sample_data/Images/churros.jpg\n",
            "23 of 100: Attempting to import /content/sample_data/Images/clam_chowder.jpg\n",
            "24 of 100: Attempting to import /content/sample_data/Images/club_sandwich.jpg\n",
            "25 of 100: Attempting to import /content/sample_data/Images/crab_cakes.jpg\n",
            "26 of 100: Attempting to import /content/sample_data/Images/creme_brulee.jpg\n",
            "27 of 100: Attempting to import /content/sample_data/Images/croque_madame.jpg\n",
            "28 of 100: Attempting to import /content/sample_data/Images/cup_cakes.jpg\n",
            "29 of 100: Attempting to import /content/sample_data/Images/deviled_eggs.jpg\n",
            "30 of 100: Attempting to import /content/sample_data/Images/donuts.jpg\n",
            "31 of 100: Attempting to import /content/sample_data/Images/dumplings.jpg\n",
            "32 of 100: Attempting to import /content/sample_data/Images/edamame.jpg\n",
            "33 of 100: Attempting to import /content/sample_data/Images/eggs_benedict.jpg\n",
            "34 of 100: Attempting to import /content/sample_data/Images/escargots.jpg\n",
            "35 of 100: Attempting to import /content/sample_data/Images/falafel.jpg\n",
            "36 of 100: Attempting to import /content/sample_data/Images/filet_mignon.jpg\n",
            "37 of 100: Attempting to import /content/sample_data/Images/fish_and_chips.jpg\n",
            "38 of 100: Attempting to import /content/sample_data/Images/foie_gras.jpg\n",
            "39 of 100: Attempting to import /content/sample_data/Images/french_fries.jpg\n",
            "40 of 100: Attempting to import /content/sample_data/Images/french_onion_soup.jpg\n",
            "41 of 100: Attempting to import /content/sample_data/Images/french_toast.jpg\n",
            "42 of 100: Attempting to import /content/sample_data/Images/fried_calamari.jpg\n",
            "43 of 100: Attempting to import /content/sample_data/Images/fried_rice.jpg\n",
            "44 of 100: Attempting to import /content/sample_data/Images/frozen_yogurt.jpg\n",
            "45 of 100: Attempting to import /content/sample_data/Images/garlic_bread.jpg\n",
            "46 of 100: Attempting to import /content/sample_data/Images/gnocchi.jpg\n",
            "47 of 100: Attempting to import /content/sample_data/Images/greek_salad.jpg\n",
            "48 of 100: Attempting to import /content/sample_data/Images/grilled_cheese_sandwich.jpg\n",
            "49 of 100: Attempting to import /content/sample_data/Images/grilled_salmon.jpg\n",
            "50 of 100: Attempting to import /content/sample_data/Images/guacamole.jpg\n",
            "51 of 100: Attempting to import /content/sample_data/Images/gyoza.jpg\n",
            "52 of 100: Attempting to import /content/sample_data/Images/hamburger.jpg\n",
            "53 of 100: Attempting to import /content/sample_data/Images/hot_and_sour_soup.jpg\n",
            "54 of 100: Attempting to import /content/sample_data/Images/hot_dog.jpg\n",
            "55 of 100: Attempting to import /content/sample_data/Images/huevos_rancheros.jpg\n",
            "56 of 100: Attempting to import /content/sample_data/Images/hummus.jpg\n",
            "57 of 100: Attempting to import /content/sample_data/Images/ice_cream.jpg\n",
            "58 of 100: Attempting to import /content/sample_data/Images/lasagna.jpg\n",
            "59 of 100: Attempting to import /content/sample_data/Images/lobster_bisque.jpg\n",
            "60 of 100: Attempting to import /content/sample_data/Images/lobster_roll_sandwich.jpg\n",
            "61 of 100: Attempting to import /content/sample_data/Images/macaroni_and_cheese.jpg\n",
            "62 of 100: Attempting to import /content/sample_data/Images/macarons.jpg\n",
            "63 of 100: Attempting to import /content/sample_data/Images/miso_soup.jpg\n",
            "64 of 100: Attempting to import /content/sample_data/Images/mussels.jpg\n",
            "65 of 100: Attempting to import /content/sample_data/Images/nachos.jpg\n",
            "66 of 100: Attempting to import /content/sample_data/Images/omelette.jpg\n",
            "67 of 100: Attempting to import /content/sample_data/Images/onion_rings.jpg\n",
            "68 of 100: Attempting to import /content/sample_data/Images/oysters.jpg\n",
            "69 of 100: Attempting to import /content/sample_data/Images/pad_thai.jpg\n",
            "70 of 100: Attempting to import /content/sample_data/Images/paella.jpg\n",
            "71 of 100: Attempting to import /content/sample_data/Images/pancakes.jpg\n",
            "72 of 100: Attempting to import /content/sample_data/Images/panna_cotta.jpg\n",
            "73 of 100: Attempting to import /content/sample_data/Images/peking_duck.jpg\n",
            "74 of 100: Attempting to import /content/sample_data/Images/pho.jpg\n",
            "75 of 100: Attempting to import /content/sample_data/Images/pizza.jpg\n",
            "76 of 100: Attempting to import /content/sample_data/Images/pork_chop.jpg\n",
            "77 of 100: Attempting to import /content/sample_data/Images/poutine.jpg\n",
            "78 of 100: Attempting to import /content/sample_data/Images/prime_rib.jpg\n",
            "79 of 100: Attempting to import /content/sample_data/Images/pulled_pork_sandwich.jpg\n",
            "80 of 100: Attempting to import /content/sample_data/Images/ramen.jpg\n",
            "81 of 100: Attempting to import /content/sample_data/Images/ravioli.jpg\n",
            "82 of 100: Attempting to import /content/sample_data/Images/red_velvet_cake.jpg\n",
            "83 of 100: Attempting to import /content/sample_data/Images/risotto.jpg\n",
            "84 of 100: Attempting to import /content/sample_data/Images/samosa.jpg\n",
            "85 of 100: Attempting to import /content/sample_data/Images/sashimi.jpg\n",
            "86 of 100: Attempting to import /content/sample_data/Images/scallops.jpg\n",
            "87 of 100: Attempting to import /content/sample_data/Images/seaweed_salad.jpg\n",
            "88 of 100: Attempting to import /content/sample_data/Images/shrimp_and_grits.jpg\n",
            "89 of 100: Attempting to import /content/sample_data/Images/spaghetti_bolognese.jpg\n",
            "90 of 100: Attempting to import /content/sample_data/Images/spaghetti_carbonara.jpg\n",
            "91 of 100: Attempting to import /content/sample_data/Images/spring_rolls.jpg\n",
            "92 of 100: Attempting to import /content/sample_data/Images/steak.jpg\n",
            "93 of 100: Attempting to import /content/sample_data/Images/strawberry_shortcake.jpg\n",
            "94 of 100: Attempting to import /content/sample_data/Images/sushi.jpg\n",
            "95 of 100: Attempting to import /content/sample_data/Images/tacos.jpg\n",
            "96 of 100: Attempting to import /content/sample_data/Images/takoyaki.jpg\n",
            "97 of 100: Attempting to import /content/sample_data/Images/tiramisu.jpg\n",
            "98 of 100: Attempting to import /content/sample_data/Images/tuna_tartare.jpg\n",
            "99 of 100: Attempting to import /content/sample_data/Images/waffles.jpg\n",
            "100\n",
            "Images loaded!100\n",
            "Creating pickle file...\n",
            "Pickle file created!\n",
            "Creating pickle file...\n",
            "Pickle file created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we'll split our data into training and testing sets\n",
        "\n",
        "\n",
        "#Load Images from pickle file\n",
        "faceImages = loadImagesFromPickle()\n",
        "filenames = loadFilenamesFromPickle()\n",
        "filenames_df = pd.DataFrame(filenames)\n",
        "#sizes = set([img.size for img in faceImages])\n",
        "\n",
        "# Now we can call our preprocessed pixel data 'X'\n",
        "X = preProcessImages(faceImages)\n",
        "\n",
        "filenames_df['username'] = filenames_df[0]\n",
        "\n",
        "#filenames_df[['username', 'number']] = filenames_df[0]\\\n",
        "#                                                            .str.replace('.jpg', '', regex=False)\\\n",
        "#                                                            .str.split('_', expand=True)\n",
        "print(filenames_df.head())\n",
        "\n",
        "y = np.array(filenames_df['username'])\n",
        "print(\"Number of classes\", len(filenames_df['username'].unique()))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "\n",
        "X_train_aug, y_train_aug = enhanceDataSetForAugmentation(X_train,y_train)\n",
        "model,y_encoder = createModel(X_train_aug, y_train_aug,20)\n",
        "#model,y_encoder = createModel(X_train, y_train,20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWOi9G7eZytA",
        "outputId": "f382582a-37ed-4b2d-becc-efc6e524a2ae"
      },
      "execution_count": 67,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Loading images from pickle file...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Loading filenames from pickle file...\n",
            "Preprocessing images...\n",
            "                0        username\n",
            "0  baby_back_ribs  baby_back_ribs\n",
            "1         baklava         baklava\n",
            "2  beef_carpaccio  beef_carpaccio\n",
            "3    beef_tartare    beef_tartare\n",
            "4      beet_salad      beet_salad\n",
            "Number of classes 100\n",
            "<class 'numpy.ndarray'>\n",
            "300 75\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 5s/step - accuracy: 0.0030 - loss: 11.4936 - val_accuracy: 0.0133 - val_loss: 4.4580 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 4s/step - accuracy: 0.0394 - loss: 9.5894 - val_accuracy: 0.0133 - val_loss: 4.4612 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 4s/step - accuracy: 0.0739 - loss: 10.5319 - val_accuracy: 0.0000e+00 - val_loss: 4.6718 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 5s/step - accuracy: 0.1178 - loss: 9.4374 - val_accuracy: 0.0133 - val_loss: 4.3834 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 5s/step - accuracy: 0.1381 - loss: 10.0158 - val_accuracy: 0.0533 - val_loss: 4.8925 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 4s/step - accuracy: 0.1876 - loss: 9.7422 - val_accuracy: 0.0933 - val_loss: 4.3652 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 4s/step - accuracy: 0.2915 - loss: 10.7780 - val_accuracy: 0.0667 - val_loss: 5.1016 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 5s/step - accuracy: 0.3958 - loss: 8.8811 - val_accuracy: 0.0533 - val_loss: 5.1113 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 5s/step - accuracy: 0.4570 - loss: 8.8858 - val_accuracy: 0.0533 - val_loss: 6.3007 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 5s/step - accuracy: 0.4504 - loss: 8.7986 - val_accuracy: 0.0667 - val_loss: 7.9640 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 4s/step - accuracy: 0.5021 - loss: 8.2758 - val_accuracy: 0.0933 - val_loss: 6.5051 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 4s/step - accuracy: 0.4575 - loss: 9.0038 - val_accuracy: 0.1333 - val_loss: 6.0761 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 5s/step - accuracy: 0.5126 - loss: 7.9824 - val_accuracy: 0.1200 - val_loss: 7.1214 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 4s/step - accuracy: 0.4602 - loss: 9.1330 - val_accuracy: 0.1467 - val_loss: 7.1426 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 5s/step - accuracy: 0.4567 - loss: 9.1476 - val_accuracy: 0.0533 - val_loss: 10.4306 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 5s/step - accuracy: 0.4721 - loss: 8.5867 - val_accuracy: 0.0667 - val_loss: 7.9169 - learning_rate: 0.0010\n",
            "Epoch 17/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 5s/step - accuracy: 0.3860 - loss: 10.1757 - val_accuracy: 0.0533 - val_loss: 9.3082 - learning_rate: 0.0010\n",
            "Epoch 18/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 4s/step - accuracy: 0.4416 - loss: 9.4252 - val_accuracy: 0.0267 - val_loss: 14.7700 - learning_rate: 0.0010\n",
            "Epoch 19/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 4s/step - accuracy: 0.4734 - loss: 8.8852 - val_accuracy: 0.0400 - val_loss: 9.7329 - learning_rate: 0.0010\n",
            "Epoch 20/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 5s/step - accuracy: 0.4439 - loss: 9.3268 - val_accuracy: 0.0667 - val_loss: 8.9706 - learning_rate: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape test data for the model\n",
        "X_test_np = []\n",
        "for img in X_test:\n",
        "    # Ensure the image has 3 channels (assuming color images)\n",
        "    if img.ndim == 2:  # If grayscale, convert to 3 channels\n",
        "        img = np.stack((img,) * 3, axis=-1)\n",
        "    # Append the image to the list\n",
        "    X_test_np.append(img)\n",
        "\n",
        "# Convert to numpy array\n",
        "X_test_np = np.array(X_test_np)\n",
        "\n",
        "# One hot encode the y data\n",
        "y_test_enc = y_encoder.transform(np.array(y_test).reshape(-1, 1))\n",
        "y_test_np = np.array(y_test_enc)\n",
        "\n",
        "print(y_test_np[0].shape, '#', y_test_np.shape)\n",
        "print(X_test_np[0].shape, '#', X_test_np.shape)\n",
        "\n",
        "# Once the number of samples match, you can evaluate the model:\n",
        "if X_test_np.shape[0] == y_test_np.shape[0]:\n",
        "  model.evaluate(X_test_np, y_test_np)\n",
        "else:\n",
        "  print(\"Error: Number of samples in X_test_np and y_test_np don't match. Cannot evaluate the model.\")"
      ],
      "metadata": {
        "id": "1QYfdrMIaw4R",
        "outputId": "bd2f378a-36fe-419e-b4f5-5b384308fdf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(75,) # (25, 75)\n",
            "(160, 160, 3) # (25, 160, 160, 3)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.0000e+00 - loss: 0.3357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the entire model\n",
        "model.save('/content/drive/My Drive/food_model.h5')"
      ],
      "metadata": {
        "id": "4iSoiguXm6o0",
        "outputId": "b75911bb-644b-4377-9458-6057a5921613",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "loaded_model = load_model('/content/drive/My Drive/food_model.h5')\n",
        "\n",
        "# Check the model summary to confirm it loaded correctly\n",
        "loaded_model.summary()"
      ],
      "metadata": {
        "id": "br-GZLuj0TK3",
        "outputId": "446fc2a4-da18-4c5a-fb69-68fb045f0cf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m158\u001b[0m, \u001b[38;5;34m158\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m156\u001b[0m, \u001b[38;5;34m156\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1557504\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │      \u001b[38;5;34m99,680,320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m)                  │           \u001b[38;5;34m4,875\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">158</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">158</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1557504</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">99,680,320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,875</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m99,704,589\u001b[0m (380.34 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,704,589</span> (380.34 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m99,704,587\u001b[0m (380.34 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,704,587</span> (380.34 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "# Load and preprocess the image\n",
        "#image_path = '/content/drive/MyDrive/sampleimages/sushi.jpg'\n",
        "image_path = '/content/drive/MyDrive/sampleimages/tacos.jpg'\n",
        "#image_path = '/content/drive/MyDrive/sampleimages/takoyaki.jpg'\n",
        "image = Image.open(image_path)\n",
        "image = image.resize((160, 160))\n",
        "image_array = img_to_array(image)\n",
        "image_array = np.expand_dims(image_array, axis=0)\n",
        "image_array = image_array / 255.0\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('/content/drive/My Drive/food_model.h5')\n",
        "class_labels = filenames_df['foodName'].tolist()\n",
        "\n",
        "# Make a prediction\n",
        "predictions = model.predict(image_array)\n",
        "predicted_class = np.argmax(predictions, axis=1)\n",
        "print(predicted_class)\n",
        "\n",
        "#print(class_labels)\n",
        "predicted_label = class_labels[predicted_class[0]]"
      ],
      "metadata": {
        "id": "mh8tFMZG0VPg",
        "outputId": "25469fed-c2b6-4b3e-8f7c-c1b0b2c5e687",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848ms/step\n",
            "[65]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "filenames = loadFilenamesFromPickle()\n",
        "filenames_df = pd.DataFrame(filenames)\n",
        "\n",
        "\n",
        "filenames_df['foodName']=filenames_df[0:]\n",
        "\n",
        "# Example class labels\n",
        "class_labels = filenames_df['foodName'].tolist()\n",
        "\n",
        "#print(class_labels)\n",
        "predicted_label = class_labels[predicted_class[0]]\n",
        "\n",
        "print(f'Predicted label: {predicted_label}')\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "vrpmhRlj95m0",
        "outputId": "cc6f358e-65a5-48cc-8416-850a3f49a62d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Loading filenames from pickle file...\n",
            "Predicted label: nachos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filenames_df.loc[filenames_df['foodName'] == 'sushi']"
      ],
      "metadata": {
        "id": "1sAbq7gfBuQd",
        "outputId": "32cc3b2b-e6bf-4f76-c4a9-9b4d633e1309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0 foodName\n",
              "94  sushi    sushi"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ce3fa1e-a7f3-4907-a244-412d7cb16084\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>foodName</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>sushi</td>\n",
              "      <td>sushi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ce3fa1e-a7f3-4907-a244-412d7cb16084')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3ce3fa1e-a7f3-4907-a244-412d7cb16084 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3ce3fa1e-a7f3-4907-a244-412d7cb16084');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"filenames_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"sushi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"foodName\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"sushi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rhIJ62HxB1_p"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}